{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.4 Modellentwicklung & 4.3.5 Evaluation\n",
    "In diesem Notebook wird eine Pipeline erstellt, mit dieser werden die Datensätze automatisiert auf verschiedene Modelle trainiert und evaluiert.\n",
    "\n",
    "\n",
    "Der DP-WGAN lieferte die besten Ergebnisse, wenn er auf ein standard skaliertes Datenset trainiert wurde.\n",
    "Die generierten synthetischen Daten sind aus diesem Grund ebenfalls in Standardverteilung.\n",
    "\n",
    "\n",
    "Aus diesem Grund wird in diesem Notebook hauptsächlich auf standard skalierten Daten gearbeitet.\n",
    "Somit sind df_train und df_test die realen, skalierten Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_auc_roc_curve(y_test, y_pred, save_path=\"\"):\n",
    "    \"\"\"For a given y_test, y_pred it plots the roc curve, with the auc score.\n",
    "    If save_path is given it will save the plot.\n",
    "    \"\"\"\n",
    "    fpr,tpr,_ = metrics.roc_curve(y_test,y_pred)\n",
    "    rocAuc = metrics.auc(fpr, tpr)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title('ROC Kurve')\n",
    "    sns.lineplot(fpr, tpr, label = 'AUC für Modell = %0.2f' % rocAuc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.ylabel('Richtig Positiv Rate')\n",
    "    plt.xlabel('Falsch Positiv Rate')\n",
    "    if save_path != \"\":\n",
    "        plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def xy_split(table:pd.DataFrame):\n",
    "    \"\"\"Takes a full Give Me some Credit Dataset\n",
    "        Returns X, y splitted Dataset\n",
    "    \"\"\"\n",
    "    table.drop(\"Unnamed: 0\", axis=1, errors=\"ignore\", inplace=True)\n",
    "    y = table[[\"SeriousDlqin2yrs\"]]\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    X = table.drop(\"SeriousDlqin2yrs\", axis=1)\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    return X, y\n",
    "\n",
    "def calc_auc_real(model, draw_curve=True, scaled=True):\n",
    "    \"\"\"Calculates the auroc value of the model on the real Testset\n",
    "    \"\"\"\n",
    "    if scaled:\n",
    "        proba = model.predict_proba(df_test_X)[:, 1]\n",
    "        if draw_curve:\n",
    "            draw_auc_roc_curve(df_test_y, proba)\n",
    "        return roc_auc_score(df_test_y, proba)\n",
    "    else:\n",
    "        proba = model.predict_proba(df_test_X_unscaled)[:, 1]\n",
    "        if draw_curve:\n",
    "            draw_auc_roc_curve(df_test_y_unscaled, proba)\n",
    "        return roc_auc_score(df_test_y_unscaled, proba)\n",
    "\n",
    "def calc_f1_real(model, scaled=True):\n",
    "    \"\"\"Calculates the f1 score of the model on the real Testset\n",
    "    \"\"\"\n",
    "    if scaled:\n",
    "        proba = model.predict(df_test_X)\n",
    "        return f1_score(df_test_y, proba)\n",
    "    else:\n",
    "        proba = model.predict(df_test_X_unscaled)\n",
    "        return f1_score(df_test_y_unscaled, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lade Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade unskalierte Originaldaten\n",
    "df_full_unscaled = pd.read_csv(\"../01_EDA_Preprocessing/output_data/processed_dataset.csv\")\n",
    "\n",
    "df_train_unscaled = pd.read_csv(\"../01_EDA_Preprocessing/output_data/full_train_processed.csv\")\n",
    "df_test_unscaled = pd.read_csv(\"../01_EDA_Preprocessing/output_data/full_test_processed.csv\")\n",
    "\n",
    "\n",
    "# Lade skalierte Originaldaten\n",
    "df_train = pd.read_csv(\"../01_EDA_Preprocessing/output_data/full_train_processed_scaled.csv\")\n",
    "df_test = pd.read_csv(\"../01_EDA_Preprocessing/output_data/full_test_processed_scaled.csv\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Synthetische Datensätze\n",
    "\n",
    "# Synthetische Trainingssets ohne Privatsphäreeinschränkungen mit unterschiedlichen Skalierungen\n",
    "df_full_no_700_s = pd.read_csv(\"../02_Data_Generation/data/full-no-700-s.csv\") # StandardScaler\n",
    "df_full_no_700_a = pd.read_csv(\"../02_Data_Generation/data/full-no-700-a.csv\") # MaxAbsScaler\n",
    "df_full_no_700_m = pd.read_csv(\"../02_Data_Generation/data/full-no-700-m.csv\") # MinMaxScaler\n",
    "df_full_no_700_r = pd.read_csv(\"../02_Data_Generation/data/full-no-700-r.csv\") # RobustScaler\n",
    "\n",
    "\n",
    "# Ab hier sind alle Datensätze Standardskaliert\n",
    "# Synthetische Daten ohne Privatsphäre Einschränkungen mit unterschiedlicher Anzahl Epochen\n",
    "df_eINF_s0_50 = pd.read_csv(\"../02_Data_Generation/data/eINF-s0-50.csv\") # 50 Epochen\n",
    "df_eINF_s0_100 = pd.read_csv(\"../02_Data_Generation/data/eINF-s0-100.csv\") # 100 Epochen\n",
    "df_eINF_s0_300 = pd.read_csv(\"../02_Data_Generation/data/eINF-s0-300.csv\") # 300 Epochen\n",
    "df_eINF_s0_500 = pd.read_csv(\"../02_Data_Generation/data/eINF-s0-500.csv\") # 500 Epochen\n",
    "df_eINF_s0_800 = pd.read_csv(\"../02_Data_Generation/data/eINF-s0-800.csv\") # 800 Epochen\n",
    "\n",
    "\n",
    "# Synthetische Daten mit unterschiedlich starken Privatsphäre Einschränkungen\n",
    "# e = Epsilon, s = Sigma\n",
    "# Epsilon 0.02\n",
    "df_e002_s60 = pd.read_csv(\"../02_Data_Generation/data/e002-s60.csv\")\n",
    "df_e002_s80 = pd.read_csv(\"../02_Data_Generation/data/e002-s80.csv\")\n",
    "df_e002_s120 = pd.read_csv(\"../02_Data_Generation/data/e002-s120.csv\")\n",
    "\n",
    "# Epsilon 0.05\n",
    "df_e005_s40 = pd.read_csv(\"../02_Data_Generation/data/e005-s40.csv\")\n",
    "df_e005_s50 = pd.read_csv(\"../02_Data_Generation/data/e005-s50.csv\")\n",
    "df_e005_s60 = pd.read_csv(\"../02_Data_Generation/data/e005-s60.csv\")\n",
    "\n",
    "# Epsilon 0.1\n",
    "df_e01_s15 = pd.read_csv(\"../02_Data_Generation/data/e01-s15.csv\")\n",
    "df_e01_s20 = pd.read_csv(\"../02_Data_Generation/data/e01-s20.csv\")\n",
    "df_e01_s25 = pd.read_csv(\"../02_Data_Generation/data/e01-s25.csv\")\n",
    "\n",
    "# Epsilon 1\n",
    "df_e1_s18 = pd.read_csv(\"../02_Data_Generation/data/e1-s18.csv\")\n",
    "df_e1_s2 = pd.read_csv(\"../02_Data_Generation/data/e1-s2.csv\")\n",
    "df_e1_s25 = pd.read_csv(\"../02_Data_Generation/data/e1-s25.csv\")\n",
    "\n",
    "# Epsilon 3\n",
    "df_e3_s09 = pd.read_csv(\"../02_Data_Generation/data/e3-s09.csv\")\n",
    "df_e3_s1 = pd.read_csv(\"../02_Data_Generation/data/e3-s1.csv\")\n",
    "df_e3_s14 = pd.read_csv(\"../02_Data_Generation/data/e3-s14.csv\")\n",
    "\n",
    "# Epsilon 5\n",
    "df_e5_s07 = pd.read_csv(\"../02_Data_Generation/data/e5-s07.csv\")\n",
    "df_e5_s08 = pd.read_csv(\"../02_Data_Generation/data/e5-s08.csv\")\n",
    "df_e5_s09 = pd.read_csv(\"../02_Data_Generation/data/e5-s09.csv\")\n",
    "\n",
    "# Epsilon 8\n",
    "df_e8_s06 = pd.read_csv(\"../02_Data_Generation/data/e8-s06.csv\")\n",
    "df_e8_s065 = pd.read_csv(\"../02_Data_Generation/data/e8-s065.csv\")\n",
    "df_e8_s07 = pd.read_csv(\"../02_Data_Generation/data/e8-s07.csv\")\n",
    "\n",
    "# Epsilon 12\n",
    "df_e12_s05 = pd.read_csv(\"../02_Data_Generation/data/e12-s05.csv\")\n",
    "df_e12_s055 = pd.read_csv(\"../02_Data_Generation/data/e12-s055.csv\")\n",
    "df_e12_s06 = pd.read_csv(\"../02_Data_Generation/data/e12-s06.csv\")\n",
    "\n",
    "# Epsilon 16\n",
    "df_e16_s05 = pd.read_csv(\"../02_Data_Generation/data/e16-s05.csv\")\n",
    "df_e16_s055 = pd.read_csv(\"../02_Data_Generation/data/e16-s055.csv\")\n",
    "df_e16_s057 = pd.read_csv(\"../02_Data_Generation/data/e16-s057.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datensets vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teile Testset in X, y auf\n",
    "df_test_X, df_test_y = xy_split(df_test)\n",
    "df_test_X_unscaled, df_test_y_unscaled = xy_split(df_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell Entwicklung 4.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alle Hyperparameter, die für das Hyperparametertuning verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"max_iter\": [50, 80, 100, 150, 200, 300],\n",
    "            \"C\": [0.1, 0.5, 0.8, 1, 3, 5, 10, 15],\n",
    "            \"class_weight\": [\"None\", \"balanced\"]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [2, 3, 5, 10, 15, 20, 30, 40, 55, 60, 70],\n",
    "            \"weights\": [\"uniform\", \"distance\"]\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [2,5,10,20,30,None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"criterion\": [\"gini\", \"entropy\"]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200, 300],\n",
    "            \"max_depth\": [5, 10, 20, None]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300, 400],\n",
    "            \"learning_rate\": [0.05, 0.07, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"DummyClassifier\": {\n",
    "        \"model\": DummyClassifier(),\n",
    "        \"params\": {\n",
    "            \"strategy\": [\"stratified\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die Parameter des am besten performenden Modelles auf den realen skalierten Daten\n",
    "- Wird ebenfalls auf den generierten Daten getestet, um Overfitting auf synthetische Daten entgegenzuwirken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_best = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"max_iter\": [200],\n",
    "            \"C\": [1],\n",
    "            \"class_weight\": [\"balanced\"]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [55],\n",
    "            \"weights\": [\"uniform\"]\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [5],\n",
    "            \"criterion\": [\"entropy\"]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [200],\n",
    "            \"max_depth\": [10]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [400],\n",
    "            \"learning_rate\": [0.05]\n",
    "        }\n",
    "    },\n",
    "    \"DummyClassifier\": {\n",
    "        \"model\": DummyClassifier(),\n",
    "        \"params\": {\n",
    "            \"strategy\": [\"stratified\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die verwendeten Modell mit den Standardwerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_standard = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"max_iter\": [100],\n",
    "            \"C\": [1],\n",
    "            \"class_weight\": [None]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [5],\n",
    "            \"weights\": [\"uniform\"]\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [None],\n",
    "            \"criterion\": [\"gini\"]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100],\n",
    "            \"max_depth\": [None]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100],\n",
    "            \"learning_rate\": [0.1]\n",
    "        }\n",
    "    },\n",
    "    \"DummyClassifier\": {\n",
    "        \"model\": DummyClassifier(),\n",
    "        \"params\": {\n",
    "            \"strategy\": [\"stratified\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstelle Evaluations Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_pipeline(X, y, scoring_para, model_definition):\n",
    "    \"\"\"Trains all Models with given Hyperparameters from model_definition with GridSearchCV for given X, y\n",
    "    Returns the best_score_, best_params_, and the best model for each Modeldefinition as a Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Start Training\")\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    # Runs GridSearchCV foreach Model from model_definition\n",
    "    for model_name, mp in model_definition.items():\n",
    "       \n",
    "        clf =  GridSearchCV(mp['model'], mp['params'], cv=5, scoring=scoring_para, verbose=1)\n",
    "        clf.fit(X, y.values.ravel())\n",
    "        \n",
    "        scores.append({\n",
    "            'model': model_name,\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_,\n",
    "            \"clf\": clf\n",
    "        })\n",
    "        print(f\"{model_name}: {clf.best_score_}, {clf.best_params_}\")\n",
    "    \n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params', \"clf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(table, scaled=True, scoring_para=\"roc_auc\", draw_curve=True, model_definition=model_params):\n",
    "    \"\"\"Takes as input a Dataset, it splits the table. It runs the _train_pipeline() for the given model_definition.\n",
    "    It gives a first look at the best result.\n",
    "    Returns all results as Dataframe.\n",
    "    \"\"\"\n",
    "    X, y = xy_split(table)\n",
    "    \n",
    "    print(\"Data Splitted\")\n",
    "    result = _train_pipeline(X, y, scoring_para, model_definition)\n",
    "    \n",
    "    best_model = result[\"clf\"][result[\"best_score\"].idxmax()]\n",
    "    \n",
    "    if scaled:\n",
    "        # Die Metriken werden auf ein Standard skaliertes Testset getestet\n",
    "        if draw_curve: \n",
    "            plot_confusion_matrix(best_model, df_test_X, df_test_y)\n",
    "        print(f\"AUC Score: {calc_auc_real(best_model, draw_curve=draw_curve)}\")\n",
    "        print(f\"F1 Score: {calc_f1_real(best_model)}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_on_real_data(models_df, scaled=True):\n",
    "    \"\"\"Takes as input the results from evaluate_pipeline()\n",
    "    It tests each model on the real Testsets with AUROC and F1 Score\n",
    "    \"\"\"\n",
    "    array = []\n",
    "    for idx, model in enumerate(models_df[\"clf\"]):\n",
    "        array.append([])\n",
    "        array[idx].append(model.estimator)\n",
    "        array[idx].append(calc_auc_real(model, draw_curve=False, scaled=scaled))\n",
    "        array[idx].append(calc_f1_real(model, scaled=scaled))\n",
    "        array[idx].append(model.best_params_)\n",
    "    df_result = pd.DataFrame(data=array,columns=['Model', 'ROC AUC', 'F1', \"Params\"])\n",
    "    df_result.loc['mean'] = df_result.mean()\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3.5 Evaluierung\n",
    "- Wende die entwickelte Evaluationspipeline auf die realen & generierten Daten an\n",
    "- GridSearchCV testet alle möglichen Kombinationen der Hyperparameter mit der Kreuzvalidierung.\n",
    "    - Die Berechnungen auf einen einzelnen Datensatz mit allen Hyperparametern, nimmt dementsprechend einiges an Zeit in Anspruch. ~1h\n",
    "    - Besonders RandomForestClassifier und GradientBoostingClassifier benötigen dabei viel Zeit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5.1\tVergleich realer Datensatz und Datensatz mit Standardverteilung\n",
    "#### Wende Pipeline auf die realen untransformierten Daten an\n",
    "- Da die Daten nicht skaliert sind, wird die Logistische Regression für kleinere max_iter Werte eine ConvergenceWarning ausgeben.\n",
    "- Aus diesen Grund werden für die Evaluierung auf den realen untransformierten Daten, für die Logistische Regression, andere Hyperparameter gewählt, als für die skalierten Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Splitted\n",
      "Start Training\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bwlx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.843249352528294, {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 300}\n",
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n",
      "KNeighbors: 0.6289005492855779, {'n_neighbors': 70, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "DecisionTreeClassifier: 0.834448380779526, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "RandomForest: 0.8557239156519383, {'max_depth': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "XGBoost: 0.8561575010580429, {'learning_rate': 0.05, 'n_estimators': 400}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "DummyClassifier: 0.5016354623563584, {'strategy': 'stratified'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.841193</td>\n",
       "      <td>0.325348</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'max_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.629261</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>{'n_neighbors': 70, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.828791</td>\n",
       "      <td>0.246471</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.851751</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>0.282379</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 400}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier()</td>\n",
       "      <td>0.505837</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751639</td>\n",
       "      <td>0.194834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model   ROC AUC        F1  \\\n",
       "0             LogisticRegression()  0.841193  0.325348   \n",
       "1           KNeighborsClassifier()  0.629261  0.000968   \n",
       "2         DecisionTreeClassifier()  0.828791  0.246471   \n",
       "3         RandomForestClassifier()  0.851751  0.249132   \n",
       "4     GradientBoostingClassifier()  0.853002  0.282379   \n",
       "5                DummyClassifier()  0.505837  0.064706   \n",
       "mean                           NaN  0.751639  0.194834   \n",
       "\n",
       "                                                 Params  \n",
       "0     {'C': 0.5, 'class_weight': 'balanced', 'max_it...  \n",
       "1            {'n_neighbors': 70, 'weights': 'distance'}  \n",
       "2     {'criterion': 'entropy', 'max_depth': 5, 'min_...  \n",
       "3                {'max_depth': 10, 'n_estimators': 300}  \n",
       "4          {'learning_rate': 0.05, 'n_estimators': 400}  \n",
       "5                            {'strategy': 'stratified'}  \n",
       "mean                                                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params_real = model_params\n",
    "model_params_real[\"LogisticRegression\"] = {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"max_iter\": [200, 300, 500, 1000],\n",
    "            \"C\": [0.1, 0.5, 0.8, 1, 3, 5, 10, 15],\n",
    "            \"class_weight\": [\"None\", \"balanced\"]\n",
    "        }\n",
    "}\n",
    "    \n",
    "result_real_unscaled = evaluate_pipeline(table=df_train_unscaled, scaled=False, model_definition=model_params_real)\n",
    "result_eINF_s0_unscaled = test_models_on_real_data(result_real_unscaled, scaled=False)\n",
    "result_eINF_s0_unscaled.head(7)\n",
    "\n",
    "# result_eINF_s0_unscaled.to_csv(\"results/eINF-s0-real-unscaled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wende die Pipeline auf die realen skalierten Daten an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimiert auf AUROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Splitted\n",
      "Start Training\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "LogisticRegression: 0.846721819754962, {'C': 15, 'class_weight': 'balanced', 'max_iter': 200}\n",
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n",
      "KNeighbors: 0.83590209897019, {'n_neighbors': 70, 'weights': 'uniform'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "DecisionTreeClassifier: 0.834448380779526, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "RandomForest: 0.8557010763432125, {'max_depth': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "result_eINF_s0 = evaluate_pipeline(df_train)\n",
    "\n",
    "test_eINF_s0 = test_models_on_real_data(result_eINF_s0)\n",
    "test_eINF_s0.head(7)\n",
    "# test_eINF_s0.to_csv(\"results/eINF-s0-real.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstelle svg Grafik vom besten Modell auf den realen skalierten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc_model = test_eINF_s0[\"clf\"][test_eINF_s0[\"best_score\"].idxmax()]\n",
    "proba = best_auc_model.predict_proba(df_test_X)[:, 1]\n",
    "\n",
    "# In der SVG Grafik ist der Hintergrund bei den Labels Transparent. Bei den Schwarzen Hintergrund sieht man desswegen die Labels nicht. \n",
    "# draw_auc_roc_curve(df_test_y, proba, save_path=\"svg/roc_curve_xgboost_real_scaled.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere Modelle optimiert auf den den F1 Score\n",
    "> Wenn optimiert auf F1, sind die F1 Werte auch etwas besser, AUROC wird etwas schlechter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eINF_s0_f1 = evaluate_pipeline(table=df_train, scoring_para=\"f1\", draw_curve=False)\n",
    "\n",
    "test_eINF_s0_f1 = test_models_on_real_data(result_eINF_s0_f1)\n",
    "test_eINF_s0_f1.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.5.2\tVergleich realer Datensatz und generierte Daten ohne Differential Privacy\n",
    "Starte die Pipeline auf jeden der Datensätze und speichere die Ergebnisse als csv Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eINF_s0_datasets = {\n",
    "    \"eINF_s0_50\": df_eINF_s0_50,\n",
    "    \"eINF_s0_100\": df_eINF_s0_100, \n",
    "    \"eINF_s0_300\": df_eINF_s0_300, \n",
    "    \"eINF_s0_500\": df_eINF_s0_500, \n",
    "    \"eINF_s0_800\": df_eINF_s0_800\n",
    "}\n",
    "\n",
    "for name, dataset in df_eINF_s0_datasets.items():\n",
    "    print(f\"Start evaluating {name}\")\n",
    "    result_models = evaluate_pipeline(table=dataset, draw_curve=False)\n",
    "    result_test_on_real = test_models_on_real_data(result_models)\n",
    "#     result_test_on_real.to_csv(f\"results/{name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.5.3\tVergleiche Datensätze mit unterschiedlichen Privatsphäre Einschränkungen\n",
    "- Definiere alle betrachteten Datensätze mit unterschiedlichen Werten für Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eX_sX_datasets = {    \n",
    "    \"e002_s60\": df_e002_s60,\n",
    "    \"e002_s80\": df_e002_s80,\n",
    "    \"e002_s120\": df_e002_s120,\n",
    "    \n",
    "    \"e005_s40\": df_e005_s40,\n",
    "    \"e005_s50\": df_e005_s50,\n",
    "    \"e005_s60\": df_e005_s60,\n",
    "    \n",
    "    \"e01_s15\": df_e01_s15,\n",
    "    \"e01_s20\": df_e01_s20,\n",
    "    \"e01_s25\": df_e01_s25,\n",
    "    \n",
    "    \"e1_s18\": df_e1_s18,\n",
    "    \"e1_s2\": df_e1_s2,\n",
    "    \"e1_s25\": df_e1_s25,\n",
    "    \n",
    "    \"e3_s09\": df_e3_s09,\n",
    "    \"e3_s1\": df_e3_s1,\n",
    "    \"e3_s14\": df_e3_s14,\n",
    "    \n",
    "    \"e5_s07\": df_e5_s07,\n",
    "    \"e5_s08\": df_e5_s08,\n",
    "    \"e5_s09\": df_e5_s09,\n",
    "    \n",
    "    \"e8_s06\": df_e8_s06,\n",
    "    \"e8_s065\": df_e8_s065,\n",
    "    \"e8_s07\": df_e8_s07,\n",
    "    \n",
    "    \"e12_s05\": df_e12_s05,\n",
    "    \"e12_s055\": df_e12_s055,\n",
    "    \"e12_s06\": df_e12_s06,\n",
    "    \n",
    "    \"e16_s05\": df_e16_s05,\n",
    "    \"e16_s055\": df_e16_s055,\n",
    "    \"e16_s057\": df_e16_s057\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste alle Datensätze mit automatischen Hyperparametertuning mit allen vorher definierten Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in eX_sX_datasets.items():\n",
    "    print(f\"Start evaluating {name}\")\n",
    "    result_models = evaluate_pipeline(table=dataset, draw_curve=False)\n",
    "    result_test_on_real = test_models_on_real_data(result_models)\n",
    "#     result_test_on_real.to_csv(f\"results/{name}-01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um Overfitting beim Hyperparametertuning auf die synthetischen Daten entgegenzuwirken:\n",
    "- Teste die Datensätze nur mit den Hyperparametern der am besten Performenden Modelle auf den realen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in eX_sX_datasets.items():\n",
    "    print(f\"Start evaluating {name}\")\n",
    "    result_models = evaluate_pipeline(table=dataset, draw_curve=False, model_definition=model_params_best)\n",
    "    result_test_on_real = test_models_on_real_data(result_models)\n",
    "#     result_test_on_real.to_csv(f\"results/{name}-02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste die Datensätze mit den Standardeinstellungen der verwendeten Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in eX_sX_datasets.items():\n",
    "    print(f\"Start evaluating {name}\")\n",
    "    result_models = evaluate_pipeline(table=dataset, draw_curve=False, model_definition=model_params_standard)\n",
    "    result_test_on_real = test_models_on_real_data(result_models)\n",
    "#     result_test_on_real.to_csv(f\"results/{name}-03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstelle Grafik mit Scores auf unterschiedlichen Epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    [0.02, 0.6184],\n",
    "    [0.05, 0.5641],\n",
    "    [0.1, 0.4982],\n",
    "    [1, 0.6150],\n",
    "    [3, 0.5314],\n",
    "    [5, 0.6777],\n",
    "    [8, 0.6858],\n",
    "    [12, 0.6509],\n",
    "    [16, 0.6968],\n",
    "]\n",
    "\n",
    "df_scores = pd.DataFrame(data=scores, columns=[\"epsilon\", \"auc\"])\n",
    "score_plot = sns.regplot(x=df_scores[\"epsilon\"], y=df_scores[\"auc\"], ci=95)\n",
    "score_plot.set_ylim(0.4, 0.9)\n",
    "score_plot.set_xlim(0, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der lineare Verlauf spiegelt nicht den realen Verlauf der Kurve da. \n",
    "- Da der AUROC Score sicherlich nicht über 1 steigen kann.\n",
    "- Es muss eine Funktion 2. Grades gezeichnet werden.\n",
    "- Dafür werden die Werte von Epsilon gleich unendlich ebenfalls mit in die Grafik aufgenommen\n",
    "- Da Epsilon unendlich jedoch nicht in die Grafik gezeichnet werden kann, wird für diese ein Epsilon Wert von 50 gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    [0.02, 0.6184],\n",
    "    [0.05, 0.5641],\n",
    "    [0.1, 0.4982],\n",
    "    [1, 0.6150],\n",
    "    [3, 0.5314],\n",
    "    [5, 0.6777],\n",
    "    [8, 0.6858],\n",
    "    [12, 0.6509],\n",
    "    [16, 0.6968],\n",
    "    [50, 0.6843], # Epsilon unendlich generiert\n",
    "    [50, 0.8405] # Epsilon unendlich real\n",
    "]\n",
    "\n",
    "df_scores = pd.DataFrame(data=scores, columns=[\"Epsilon\", \"AUROC\"])\n",
    "plt.figure(figsize=(6,4))\n",
    "score_plot = sns.regplot(x=df_scores[\"Epsilon\"], y=df_scores[\"AUROC\"], ci=95, order=2)\n",
    "\n",
    "score_plot.set_ylim(0.4, 0.9)\n",
    "score_plot.set_xlim(0, 17)\n",
    "# plt.savefig(\"svg/scores_for_different_epsilon.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot mit F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 Werte sind nicht die echten, es wurde lediglich getestet \n",
    "# wie die Grafik in etwa aussehen würde\n",
    "scores = [      \n",
    "    [0.02, 0.6184, 0.16],\n",
    "    [0.05, 0.5641, 0.15],\n",
    "    [0.1, 0.4982, 0.08],\n",
    "    [1, 0.6150, 0.16],\n",
    "    [3, 0.5314, 0.13],\n",
    "    [5, 0.6777, 0.18],\n",
    "    [8, 0.6858, 0.19],\n",
    "    [12, 0.6509, 0.18],\n",
    "    [16, 0.6968, 0.20], \n",
    "    [50, 0.6843, 0.2083], # Epsilon unendlich generiert\n",
    "    [50, 0.8405, 0.2675] # Epsilon unendlich real\n",
    "]\n",
    "\n",
    "df_scores = pd.DataFrame(data=scores, columns=[\"Epsilon\", \"ROC AUC\", \"F1\"])\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "score_plot = sns.regplot(x=df_scores[\"Epsilon\"], y=df_scores[\"ROC AUC\"], ci=96, order=2)\n",
    "score_plot = sns.regplot(x=df_scores[\"Epsilon\"], y=df_scores[\"F1\"], ci=96, order=2)\n",
    "\n",
    "score_plot.set_ylim(0, 0.9)\n",
    "score_plot.set_xlim(0, 16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstelle Konfusionsmatrix für bestes Modell auf realen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1, class_weight=\"balanced\", max_iter=200)\n",
    "X_train, y_train = xy_split(df_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "con_matrix = plot_confusion_matrix(model, df_test_X, df_test_y)\n",
    "plt.xlabel('Vorhersage')\n",
    "plt.ylabel(\"Korrekte Werte\")\n",
    "\n",
    "# plt.savefig(\"svg/best_plot_confusion_matrix.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Errechne Recall und Percision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(df_test_y, model.predict(df_test_X))\n",
    "precision = precision_score(df_test_y, model.predict(df_test_X))\n",
    "\n",
    "print(f\"Precision = {precision}, und Recall = {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fertig\n",
    "\n",
    "- Ab hier Tests die es nicht in die Arbeit geschafft haben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welche Prediction erreicht ein Modell trainiert auf syn getestet auf syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "X, y = xy_split(df_e001_s50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "print(f\"Matrix des Models auf realen Daten: AUC = {calc_auc_real(model, draw_curve=False)}\")\n",
    "plot_confusion_matrix(model, df_test_X, df_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste Qualität der Daten\n",
    "- Kann einen Modell reale von synthetischen Daten unterscheiden?\n",
    "- Stellt quasi den Diskriminator einer GAN Struktur dar.\n",
    "> Die Logistische Regression kann nicht unterscheiden, der GradientBoostingClassifier jedoch sehr wohl, mit sehr guter Genauigkeit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_real_syn(df_real, df_syn):\n",
    "    df_real_c = df_real.copy()\n",
    "    df_syn_c = df_syn.copy()\n",
    "    df_syn_c.drop(\"Unnamed: 0\", axis=1, inplace=True, errors=\"ignore\")\n",
    "    df_real_c[\"real\"] = 1\n",
    "    df_syn_c[\"real\"] = 0\n",
    "    df_result = df_real_c.append(df_syn_c, ignore_index=True)\n",
    "    df_result = df_result.sample(frac=1) # Shuffle\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = combine_real_syn(df_train, df_eINF_s0_100)\n",
    "\n",
    "X_com = df_com.drop(\"real\", axis=1)\n",
    "y_com = df_com[\"real\"]\n",
    "\n",
    "X_train_com, X_test_com, y_train_com, y_test_com = train_test_split(X_com, y_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_com, y_train_com)\n",
    "print(model.score(X_test_com, y_test_com))\n",
    "plot_confusion_matrix(model, X_test_com, y_test_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_com, y_train_com)\n",
    "print(model.score(X_test_com, y_test_com))\n",
    "plot_confusion_matrix(model, X_test_com, y_test_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaler Aufbau für einen einzelnen Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = xy_split(df_e3_s09)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "# model = DummyClassifier(strategy=\"most_frequent\")\n",
    "# model = GradientBoostingClassifier(learning_rate=0.1, n_estimators=400)\n",
    "# model = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Teste Modell auf reale Daten\n",
    "print(model.score(df_test_X, df_test_y))\n",
    "plot_confusion_matrix(model, df_test_X, df_test_y)\n",
    "draw_auc_roc_curve(df_test_y, model.predict_proba(df_test_X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
